# ============================================================
# DotBot Server — Environment Variables
# ============================================================
# Copy this to .env and fill in your API keys:
#   cp .env.example .env
#   nano .env
#
# Minimum to start: ONE LLM key (DeepSeek recommended).
# Get keys:
#   DeepSeek:    https://platform.deepseek.com/api_keys
#   Gemini:      https://aistudio.google.com/apikey
#   Anthropic:   https://console.anthropic.com/settings/keys
#   OpenAI:      https://platform.openai.com/api-keys
#   ScrapingDog: https://www.scrapingdog.com/

# --- Server Ports ---
PORT=3000                        # HTTP API port
WS_PORT=3001                     # WebSocket port
# (If using Caddy, these stay internal — don't expose directly)

# --- Public URL (required for remote deployments) ---
# PUBLIC_URL=https://server.getmy.bot  # Used for credential entry page URLs
# If unset, defaults to http://localhost:$PORT (fine for local dev)

# --- LLM Providers (at least ONE required) ---
XAI_API_KEY=                     # Primary — workhorse, intake, assistant (recommended)
DEEPSEEK_API_KEY=                # Fallback workhorse — cheapest option
GEMINI_API_KEY=                  # Deep context (1M tokens), image generation
ANTHROPIC_API_KEY=               # Architect — complex reasoning, planning
# OPENAI_API_KEY=                # Optional fallback for multiple roles

# --- Premium Tools (optional) ---
# SCRAPING_DOG_API_KEY=          # ScrapingDog — 42 APIs (Google Search, Amazon, YouTube, etc.)

# --- Security (IMPORTANT for production) ---
# ADMIN_API_KEY=                 # Protects HTTP admin endpoints (/api/scheduler, /api/memory, etc.)
                                 # Generate: openssl rand -hex 32
                                 # Leave blank only for local dev

# --- Advanced (usually leave defaults) ---
DB_DIR=/home/dotbot/.bot/server-data     # SQLite database location (set explicitly for multi-user consistency)
# LOG_DIR=/home/dotbot/.bot/server-logs  # Server log files
